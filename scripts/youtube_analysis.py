# -*- coding: utf-8 -*-
"""Youtube_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zd1KMxSiQ5B8AJs9zKNxls9F-hx11zEw
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount("/content/drive")

comments = pd.read_csv('/content/drive/MyDrive/Projects Py, SQL, PBI/Mine P5 Youtube Analysis - Python/UScomments.csv', on_bad_lines='skip')



comments.head()

## lets find out missing values in your data
comments.isnull().sum()

## drop missing values as we have very few & lets update dataframe as well..
comments.dropna(inplace=True)

comments.isnull().sum()

from textblob import TextBlob

TextBlob("Logan Paul it's yo big day ‼️‼️‼️").sentiment.polarity

### its a neutral sentence !

comments.shape

## for those of you who dont have good specifications , considering sample of data is a good option !

sample_df = comments[0:1000]

sample_df.shape

polarity = []

for comment in comments['comment_text']:
    try:
        polarity.append(TextBlob(comment).sentiment.polarity)
    except:
        polarity.append(0)

len(polarity)

comments['polarity']  = polarity

### Inserting polarity values into comments dataframe while defining feature name as "polarity"

"""## 3..  Wordcloud Analysis of your data

"""

### Lets perform EDA for the highly Positve sentences ie Polarity value will be 1

filter1 = comments['polarity']==1
comments_positive = comments[filter1]
filter2 = comments['polarity']==-1
comments_negative = comments[filter2]

comments_positive.head(5)

comments_negative.head(5)

from wordcloud import WordCloud , STOPWORDS
set(STOPWORDS)
comments['comment_text']
type(comments['comment_text'])
### for wordcloud , we need to frame our 'comment_text' feature into string ..
total_comments_positive = ' '.join(comments_positive['comment_text'])
wordcloud = WordCloud(stopwords=set(STOPWORDS)).generate(total_comments_positive)
plt.imshow(wordcloud)
plt.axis('off')
### Conclusion-->> positive Users are emphasizing more on best , awesome , perfect , amazing , look , happy  etc..

total_comments_negative = ' '.join(comments_negative['comment_text'])
wordcloud2 = WordCloud(stopwords=set(STOPWORDS)).generate(total_comments_negative)
plt.imshow(wordcloud2)
plt.axis('off')

### Conclusion-->> Negative Users are emphasizing more on Terrible , worst ,horrible ,boring , disgusting etc..

"""## 4.. Perform Emoji's Analysis"""

!pip install emoji==2.2.0 ## 2.2.0 is a most stable version till date , hence installing this version makes sense !
import emoji

emoji.__version__

comments['comment_text'].head(6)

all_emojis_list = []

for comment in comments['comment_text'].dropna(): ## in case u have missing values , call dropna()
    for char in comment:
        if char in emoji.EMOJI_DATA:
            all_emojis_list.append(char)

all_emojis_list[0:10]

### NOw we have to compute frequencies of each & every emoji in "all_emojis_list"..

from collections import Counter
Counter(all_emojis_list).most_common(10)

freqs = [Counter(all_emojis_list).most_common(10)[i][1] for i in range(10)]

freqs

import plotly.graph_objs as go
from plotly.offline import iplot

trace = go.Bar(x=emojis , y=freqs)

iplot([trace])

## Conclusions : Majority of the customers are happy as most of them are using emojis like: funny , love , heart , outstanding..